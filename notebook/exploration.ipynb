{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset ogbg-molhiv Project"
   ]
  },
  {
   "source": [
    "## Introduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Introduction of dataset taken from https://ogb.stanford.edu/docs/graphprop/#ogbg-mol"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Graph: The ogbg-molhiv and ogbg-molpcba datasets are two molecular property prediction datasets of different sizes: ogbg-molhiv (small) and ogbg-molpcba (medium). They are adopted from the MoleculeNet [1], and are among the largest of the MoleculeNet datasets. All the molecules are pre-processed using RDKit [2]. Each graph represents a molecule, where nodes are atoms, and edges are chemical bonds. Input node features are 9-dimensional, containing atomic number and chirality, as well as other additional atom features such as formal charge and whether the atom is in the ring or not. The full description of the features is provided in code. The script to convert the SMILES string [3] to the above graph object can be found here. Note that the script requires RDkit to be installed. The script can be used to pre-process external molecule datasets so that those datasets share the same input feature space as the OGB molecule datasets. This is particularly useful for pre-training graph models, which has great potential to significantly increase generalization performance on the (downstream) OGB datasets [4].  \n",
    "\n",
    "Beside the two main datasets, we additionally provide 10 smaller datasets from MoleculeNet. They are ogbg-moltox21, ogbg-molbace, ogbg-molbbbp, ogbg-molclintox, ogbg-molmuv, ogbg-molsider, and ogbg-moltoxcast for (multi-task) binary classification, and ogbg-molesol, ogbg-molfreesolv, and ogbg-mollipo for regression. Evaluators are also provided for these datasets. These datasets can be used to stress-test molecule-specific methods or transfer learning [4].  \n",
    "\n",
    "For encoding these raw input features, we prepare simple modules called AtomEncoder and BondEncoder. They can be used as follows to embed raw atom and bond features to obtain atom_emb and bond_emb.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Prediction task: The task is to predict the target molecular properties as accurately as possible, where the molecular properties are cast as binary labels, e.g, whether a molecule inhibits HIV virus replication or not. Note that some datasets (e.g., ogbg-molpcba) can have multiple tasks, and can contain nan that indicates the corresponding label is not assigned to the molecule. For evaluation metric, we closely follow [2]. Specifically, for ogbg-molhiv, we use ROC-AUC for evaluation. For ogbg-molpcba, as the class balance is extremely skewed (only 1.4% of data is positive) and the dataset contains multiple classification tasks, we use the Average Precision (AP) averaged over the tasks as the evaluation metric.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Dataset splitting: We adopt the scaffold splitting procedure that splits the molecules based on their two-dimensional structural frameworks. The scaffold splitting attempts to separate structurally different molecules into different subsets, which provides a more realistic estimate of model performance in prospective experimental settings [1].\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Loader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = PygGraphPropPredDataset(name = \"ogbg-molhiv\", root='../')\n",
    " \n",
    "split_idx = dataset.get_idx_split() \n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for step, data in enumerate(train_loader):\n",
    "#     print(f'Step {step + 1}:')\n",
    "#     print('=======')\n",
    "#     print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "#     print(data)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COO stores a list of (row, column, value) tuples. Ideally, the entries are sorted first by row index and then by column index, to improve random access times. This is another format that is good for incremental matrix construction.  \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.x: Node feature matrix with shape [num_nodes, num_node_features]  \n",
    "data.edge_index: Graph connectivity in COO format with shape `[2, num_edges]` and type torch.long i.e `[2,3]` node soucre (2) goes to destination node (3).  \n",
    "data.edge_attr: Edge feature matrix with shape `[num_edges, num_edge_features]`.  \n",
    "data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(41127,\n",
       " Data(edge_attr=[40, 3], edge_index=[2, 40], x=[19, 9], y=[1, 1]),\n",
       " tensor(True))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(dataset), dataset[0], dataset[0].is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0]), tensor([0, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dataset[0].edge_attr[0], dataset[0].edge_index[:,0]"
   ]
  },
  {
   "source": [
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Dataset: {dataset}:')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "print('======================')\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print(data)\n",
    "print('==============================================================')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset: PygGraphPropPredDataset(41127):\nNumber of graphs: 41127\nNumber of features: 9\nNumber of classes: 2\n======================\nData(edge_attr=[40, 3], edge_index=[2, 40], x=[19, 9], y=[1, 1])\n==============================================================\nNumber of nodes: 19\nNumber of edges: 40\nAverage node degree: 2.11\nContains self-loops: False\nIs undirected: True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of graphs = 41127\n# of classes = 2\n# of node features = 9\n# of edge features = 3\n# of tasks = 1\n"
     ]
    }
   ],
   "source": [
    "print('# of graphs = {0}\\n# of classes = {1}\\n# of node features = {2}\\n# of edge features = {3}'.\\\n",
    "         format(len(dataset), dataset.num_classes, dataset.num_node_features, dataset.num_edge_features))\n",
    "\n",
    "if isinstance(dataset, PygGraphPropPredDataset): # OGB datasets\n",
    "    print('# of tasks = {}'.format(dataset.num_tasks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first graph has 19 nodes, each one having 9 features. The graph has 40 edges, each one having 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([19, 9]),\n",
       " tensor([[ 5,  0,  4,  5,  3,  0,  2,  0,  0],\n",
       "         [ 5,  0,  4,  5,  2,  0,  2,  0,  0],\n",
       "         [ 5,  0,  3,  5,  0,  0,  1,  0,  1],\n",
       "         [ 7,  0,  2,  6,  0,  0,  1,  0,  1],\n",
       "         [28,  0,  4,  2,  0,  0,  5,  0,  1],\n",
       "         [ 7,  0,  2,  6,  0,  0,  1,  0,  1],\n",
       "         [ 5,  0,  3,  5,  0,  0,  1,  0,  1],\n",
       "         [ 5,  0,  4,  5,  2,  0,  2,  0,  0],\n",
       "         [ 5,  0,  4,  5,  3,  0,  2,  0,  0],\n",
       "         [ 5,  0,  4,  5,  2,  0,  2,  0,  1],\n",
       "         [ 7,  0,  2,  6,  0,  0,  1,  0,  1],\n",
       "         [ 5,  0,  3,  5,  0,  0,  1,  0,  1],\n",
       "         [ 5,  0,  4,  5,  2,  0,  2,  0,  0],\n",
       "         [ 5,  0,  4,  5,  3,  0,  2,  0,  0],\n",
       "         [ 5,  0,  4,  5,  2,  0,  2,  0,  1],\n",
       "         [ 5,  0,  3,  5,  0,  0,  1,  0,  1],\n",
       "         [ 5,  0,  4,  5,  2,  0,  2,  0,  0],\n",
       "         [ 5,  0,  4,  5,  3,  0,  2,  0,  0],\n",
       "         [ 7,  0,  2,  6,  0,  0,  1,  0,  1]]),\n",
       " torch.Size([2, 40]),\n",
       " tensor([[ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  6,  9,\n",
       "           4, 10, 10, 11, 11, 12, 12, 13, 11, 14, 14, 15, 15, 16, 16, 17, 15, 18,\n",
       "           9,  2, 18,  4],\n",
       "         [ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  6,  5,  7,  6,  8,  7,  9,  6,\n",
       "          10,  4, 11, 10, 12, 11, 13, 12, 14, 11, 15, 14, 16, 15, 17, 16, 18, 15,\n",
       "           2,  9,  4, 18]]),\n",
       " torch.Size([40, 3]),\n",
       " tensor([[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]),\n",
       " tensor([[0]]))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dataset[0].x.shape, dataset[0].x, dataset[0].edge_index.shape, dataset[0].edge_index, dataset[0].edge_attr.shape, dataset[0].edge_attr, dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dataset.num_classes, dataset[100].y.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([19, 100]), torch.Size([40, 100]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "atom_encoder = AtomEncoder(emb_dim = 100)\n",
    "bond_encoder = BondEncoder(emb_dim = 100)\n",
    "\n",
    "x, edge_attr = dataset[0].x, dataset[0].edge_attr\n",
    "atom_emb = atom_encoder(x) # x is input atom feature\n",
    "edge_emb = bond_encoder(edge_attr) # edge_attr is input edge feature\n",
    "atom_emb.shape, edge_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule = dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "66007789510755f23f6c779e20191defd8a9d3b5da16b531e003417902a1fc59"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}